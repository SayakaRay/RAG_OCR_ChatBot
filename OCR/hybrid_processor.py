# OCR/hybrid_processor.py (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏ä‡πâ Google Vision API)

import os
import io
import base64
from pathlib import Path
from PIL import Image
import torch
import fitz  # PyMuPDF
from dotenv import load_dotenv
import json
from bs4 import BeautifulSoup
import traceback
import time
import random
import math
import requests

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: Surya (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ API ‡πÉ‡∏´‡∏°‡πà) ---
DEVICE = "cpu"
LAYOUT_PREDICTOR = None

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variables ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Surya
os.environ['TORCH_DEVICE'] = DEVICE
os.environ['LAYOUT_BATCH_SIZE'] = '2'  # ‡∏•‡∏î batch size ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CPU
os.environ['SURYA_MODEL_PATH'] = './models'  # path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î

def _initialize_surya_models():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Layout ‡∏Ç‡∏≠‡∏á Surya (‡πÉ‡∏ä‡πâ LayoutPredictor ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà)
    """
    global LAYOUT_PREDICTOR
    if LAYOUT_PREDICTOR is None:
        print(f"[INFO] Initializing Surya Layout Model on {DEVICE} (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà)...")
        try:
            # ‡πÉ‡∏ä‡πâ LayoutPredictor ‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà
            from surya.layout import LayoutPredictor
            
            LAYOUT_PREDICTOR = LayoutPredictor()
            print("[INFO] ‚úÖ Surya Layout Model loaded successfully.")
        except ImportError as e:
            print(f"[ERROR] ‚ùå ImportError occurred. Details: {e}")
            # ‡∏û‡∏¥‡∏°‡∏û‡πå Path ‡∏ó‡∏µ‡πà Python ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏µ‡∏ö‡∏±‡∏Å
            import sys
            print("Python search paths (sys.path):")
            for p in sys.path:
                print(f"- {p}")
            raise
        except Exception as e:
            print(f"[ERROR] ‚ùå Failed to load Surya model: {e}")
            traceback.print_exc()
            raise

def _get_reading_order_score(bbox, image_width, image_height):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô (‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏Ç‡∏ß‡∏≤ ‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á)
    ‡πÉ‡∏ä‡πâ grid-based approach ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
    """
    x1, y1, x2, y2 = bbox
    
    # ‡πÉ‡∏ä‡πâ‡∏à‡∏∏‡∏î‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á bbox ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
    center_x = (x1 + x2) / 2
    center_y = (y1 + y2) / 2
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô grid ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡πÅ‡∏ñ‡∏ß
    # ‡πÉ‡∏ä‡πâ row height ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 1/20 ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏´‡∏ô‡πâ‡∏≤
    row_height = image_height / 20
    row_index = int(center_y / row_height)
    
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏´‡∏•‡∏±‡∏Å: ‡πÅ‡∏ñ‡∏ß (row) ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å
    # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏≠‡∏á: ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á x ‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
    score = (row_index * 10000) + center_x
    
    return score

def _merge_overlapping_boxes(elements, overlap_threshold=0.7):
    """
    ‡∏£‡∏ß‡∏° bounding boxes ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    """
    if not elements:
        return elements
    
    def calculate_overlap_ratio(bbox1, bbox2):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 bbox"""
        x1_1, y1_1, x2_1, y2_1 = bbox1
        x1_2, y1_2, x2_2, y2_2 = bbox2
        
        # ‡∏´‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
        x1_overlap = max(x1_1, x1_2)
        y1_overlap = max(y1_1, y1_2)
        x2_overlap = min(x2_1, x2_2)
        y2_overlap = min(y2_1, y2_2)
        
        if x1_overlap >= x2_overlap or y1_overlap >= y2_overlap:
            return 0.0
        
        overlap_area = (x2_overlap - x1_overlap) * (y2_overlap - y1_overlap)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        
        return overlap_area / min(area1, area2)
    
    merged_elements = []
    used_indices = set()
    
    for i, elem1 in enumerate(elements):
        if i in used_indices:
            continue
            
        merged_bbox = list(elem1['bbox'])
        merged_labels = [elem1['label']]
        merged_confidences = [elem1['confidence']]
        group_indices = [i]
        
        # ‡∏´‡∏≤‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        for j, elem2 in enumerate(elements[i+1:], i+1):
            if j in used_indices:
                continue
                
            overlap_ratio = calculate_overlap_ratio(elem1['bbox'], elem2['bbox'])
            if overlap_ratio >= overlap_threshold:
                # ‡∏£‡∏ß‡∏° bbox ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ union
                merged_bbox[0] = min(merged_bbox[0], elem2['bbox'][0])  # x1
                merged_bbox[1] = min(merged_bbox[1], elem2['bbox'][1])  # y1
                merged_bbox[2] = max(merged_bbox[2], elem2['bbox'][2])  # x2
                merged_bbox[3] = max(merged_bbox[3], elem2['bbox'][3])  # y2
                
                merged_labels.append(elem2['label'])
                merged_confidences.append(elem2['confidence'])
                group_indices.append(j)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß
        used_indices.update(group_indices)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á element ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß
        merged_element = {
            'bbox': merged_bbox,
            'label': max(set(merged_labels), key=merged_labels.count),  # ‡πÉ‡∏ä‡πâ label ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
            'confidence': sum(merged_confidences) / len(merged_confidences),  # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ confidence
            'merged_count': len(group_indices)
        }
        merged_elements.append(merged_element)
    
    print(f"   -> Merged {len(elements)} elements into {len(merged_elements)} elements")
    return merged_elements

def _expand_bbox_for_context(bbox, image_width, image_height, expansion_ratio=0.05):
    """
    ‡∏Ç‡∏¢‡∏≤‡∏¢ bounding box ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
    """
    x1, y1, x2, y2 = bbox
    
    width = x2 - x1
    height = y2 - y1
    
    # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ï‡∏≤‡∏°‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    expand_x = width * expansion_ratio
    expand_y = height * expansion_ratio
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì bbox ‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï
    new_x1 = max(0, int(x1 - expand_x))
    new_y1 = max(0, int(y1 - expand_y))
    new_x2 = min(image_width, int(x2 + expand_x))
    new_y2 = min(image_height, int(y2 + expand_y))
    
    return [new_x1, new_y1, new_x2, new_y2]

def _surya_layout_analysis(pil_image):
    """
    ‡πÉ‡∏ä‡πâ Surya ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Layout ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á BBoxes ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤
    ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏Ç‡∏ß‡∏≤ ‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏° bbox ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
    """
    print("   -> Running Surya layout detection...")
    
    try:
        # ‡πÉ‡∏ä‡πâ LayoutPredictor ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ predict
        layout_predictions = LAYOUT_PREDICTOR([pil_image])
        
        elements = []
        # ‡∏î‡∏∂‡∏á bboxes ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        page_prediction = layout_predictions[0]
        
        if hasattr(page_prediction, 'bboxes') and page_prediction.bboxes:
            for bbox_obj in page_prediction.bboxes:
                # ‡πÅ‡∏õ‡∏•‡∏á bbox format ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                elements.append({
                    "bbox": bbox_obj.bbox,  # [x1, y1, x2, y2]
                    "label": getattr(bbox_obj, 'label', 'Text'),  # ‡πÉ‡∏ä‡πâ label ‡∏à‡∏≤‡∏Å Surya ‡∏´‡∏£‡∏∑‡∏≠ default ‡πÄ‡∏õ‡πá‡∏ô 'Text'
                    "confidence": getattr(bbox_obj, 'confidence', 1.0)  # confidence score
                })
        else:
            print("   -> ‚ö†Ô∏è No bboxes found in layout prediction")
            # fallback: ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            width, height = pil_image.size
            elements.append({
                "bbox": [0, 0, width, height],
                "label": "Text",
                "confidence": 1.0
            })
        
        print(f"   -> Found {len(elements)} initial layout elements")
        
        # ‡∏£‡∏ß‡∏° bounding boxes ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
        elements = _merge_overlapping_boxes(elements, overlap_threshold=0.6)
        
        # ‡∏Ç‡∏¢‡∏≤‡∏¢ bbox ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏ö
        image_width, image_height = pil_image.size
        for elem in elements:
            elem['bbox'] = _expand_bbox_for_context(
                elem['bbox'], image_width, image_height, expansion_ratio=0.02
            )
        
        # ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° reading order (‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏Ç‡∏ß‡∏≤ ‡∏ö‡∏ô‡∏•‡∏á‡∏•‡πà‡∏≤‡∏á)
        elements.sort(key=lambda e: _get_reading_order_score(e['bbox'], image_width, image_height))
        
        print(f"   -> Final: {len(elements)} layout elements (merged and sorted)")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö debug
        for i, elem in enumerate(elements):
            bbox = elem['bbox']
            center_x = (bbox[0] + bbox[2]) / 2
            center_y = (bbox[1] + bbox[3]) / 2
            print(f"      Element {i+1}: {elem['label']} at center({center_x:.0f}, {center_y:.0f})")
        
        return elements
        
    except Exception as e:
        print(f"   -> ‚ùå Error in layout analysis: {e}")
        traceback.print_exc()
        # fallback: ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        width, height = pil_image.size
        return [{
            "bbox": [0, 0, width, height],
            "label": "Text",
            "confidence": 1.0
        }]

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: Google Vision API ---
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

if not GOOGLE_API_KEY:
    print("‚ö†Ô∏è Warning: GOOGLE_API_KEY not found in environment variables")

def convert_html_tables_to_markdown(html_content: str) -> str:
    """‡πÅ‡∏õ‡∏•‡∏á HTML tables ‡πÄ‡∏õ‡πá‡∏ô Markdown format"""
    if '<table>' not in html_content:
        return html_content
    soup = BeautifulSoup(html_content, 'lxml')
    for table in soup.find_all('table'):
        markdown_table = ""
        headers = [th.get_text(strip=True).replace("\n", " ") for th in table.find_all('th')]
        tr = table.find('tr')
        if not headers and tr:
             headers = [td.get_text(strip=True).replace("\n", " ") for td in tr.find_all('td')]
        if headers:
            markdown_table += "| " + " | ".join(headers) + " |\n"
            markdown_table += "| " + " | ".join(['---'] * len(headers)) + " |\n"
            start_row = 1
        else:
            start_row = 0
        rows = table.find_all('tr')
        for row in rows[start_row:]:
            columns = [td.get_text(strip=True).replace("\n", " ") for td in row.find_all('td')]
            if len(columns) == len(headers) or not headers:
                markdown_table += "| " + " | ".join(columns) + " |\n"
        if markdown_table:
            table.replace_with(markdown_table)
    return str(soup)

def _detect_text_type(element_info):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ TEXT_DETECTION ‡∏´‡∏£‡∏∑‡∏≠ DOCUMENT_TEXT_DETECTION
    """
    if not element_info or not element_info.get('label'):
        return 'DOCUMENT_TEXT_DETECTION'  # default
    
    label = element_info['label'].lower()
    
    # ‚úÖ FIX: ‡πÉ‡∏ä‡πâ 'DOCUMENT_TEXT_DETECTION' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠
    if 'handwriting' in label or 'handwritten' in label or 'hand' in label:
        return 'DOCUMENT_TEXT_DETECTION'
    
    # ‡πÉ‡∏ä‡πâ DOCUMENT_TEXT_DETECTION ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á
    elif any(keyword in label for keyword in ['table', 'document', 'paragraph', 'column']):
        return 'DOCUMENT_TEXT_DETECTION'
    
    # ‡πÉ‡∏ä‡πâ TEXT_DETECTION ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    else:
        return 'TEXT_DETECTION'

def _format_vision_response(response_data, element_info=None):
    """
    ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Google Vision API ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Markdown
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á TEXT_DETECTION ‡πÅ‡∏•‡∏∞ DOCUMENT_TEXT_DETECTION
    """
    try:
        responses = response_data.get('responses', [])
        if not responses:
            return "[No response from Vision API]"
        
        response = responses[0]
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö error
        if 'error' in response:
            return f"[Vision API Error: {response['error'].get('message', 'Unknown error')}]"
        
        # ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å fullTextAnnotation ‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DOCUMENT_TEXT_DETECTION)
        if 'fullTextAnnotation' in response:
            full_text = response['fullTextAnnotation'].get('text', '').strip()
            if full_text:
                # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô markdown ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á element
                if element_info and element_info.get('label'):
                    label = element_info['label'].lower()
                    if 'title' in label or 'header' in label:
                        # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô header
                        lines = full_text.split('\n')
                        if lines:
                            full_text = f"### {lines[0]}\n" + '\n'.join(lines[1:])
                    elif 'table' in label:
                        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ)
                        full_text = _try_format_as_table(full_text)
                
                return full_text
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ fullTextAnnotation ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ textAnnotations
        if 'textAnnotations' in response:
            text_annotations = response['textAnnotations']
            if text_annotations:
                # textAnnotations[0] ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                full_text = text_annotations[0].get('description', '').strip()
                return full_text if full_text else "[No text detected]"
        
        return "[No text found in response]"
        
    except Exception as e:
        print(f"    -> ‚ùå Error formatting Vision response: {e}")
        return f"[Error formatting response: {str(e)}]"

def _try_format_as_table(text):
    """
    ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á Markdown
    """
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    if len(lines) < 2:
        return text
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏°‡∏µ pattern ‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô)
    word_counts = [len(line.split()) for line in lines]
    avg_words = sum(word_counts) / len(word_counts)
    
    # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    if all(abs(count - avg_words) <= 2 for count in word_counts) and avg_words >= 2:
        try:
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            max_cols = max(word_counts)
            table_lines = []
            
            # Header
            header_parts = lines[0].split()
            while len(header_parts) < max_cols:
                header_parts.append("")
            table_lines.append("| " + " | ".join(header_parts) + " |")
            table_lines.append("| " + " | ".join(['---'] * len(header_parts)) + " |")
            
            # Rows
            for line in lines[1:]:
                parts = line.split()
                while len(parts) < max_cols:
                    parts.append("")
                table_lines.append("| " + " | ".join(parts[:max_cols]) + " |")
            
            return '\n'.join(table_lines)
        except:
            pass
    
    return text

def _google_vision_process_crop(pil_image_crop, element_info=None, retry_count=0, max_retries=3):
    """
    ‡πÉ‡∏ä‡πâ Google Vision API ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà crop ‡∏°‡∏≤
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á text detection ‡πÅ‡∏•‡∏∞ handwriting detection
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö retry ‡πÅ‡∏•‡∏∞ delay ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ rate limit
    """
    if not GOOGLE_API_KEY:
        return "[Error: GOOGLE_API_KEY not configured]"
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° delay ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á request ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á rate limit
    base_delay = 0.5  # 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (Google Vision ‡∏°‡∏µ rate limit ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Typhoon)
    jitter = random.uniform(0.1, 0.3)
    delay = base_delay + jitter + (retry_count * 1)
    
    if retry_count > 0:  # ‡πÅ‡∏™‡∏î‡∏á delay ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô retry
        print(f"    -> Waiting {delay:.1f}s before Vision request (attempt {retry_count + 1}/{max_retries + 1})...")
    
    time.sleep(delay)
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô base64
    buffered = io.BytesIO()
    pil_image_crop.save(buffered, format="PNG")
    base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
    detection_type = _detect_text_type(element_info)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á request payload
    request_payload = {
        "requests": [
            {
                "image": {
                    "content": base64_image
                },
                "features": [
                    {
                        "type": detection_type,
                        "maxResults": 50  # ‡πÄ‡∏û‡∏¥‡πà‡∏° maxResults ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
                    }
                ]
            }
        ]
    }
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô DOCUMENT_TEXT_DETECTION ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏° imageContext ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö language hints (‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏£‡∏ß‡∏°‡∏•‡∏≤‡∏¢‡∏°‡∏∑‡∏≠‡∏î‡πâ‡∏ß‡∏¢)
    if detection_type == 'DOCUMENT_TEXT_DETECTION':
        request_payload["requests"][0]["imageContext"] = {
            "languageHints": ["th", "en"]  # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        }
    
    vision_api_url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_API_KEY}"
    
    try:
        response = requests.post(
            vision_api_url,
            headers={'Content-Type': 'application/json'},
            json=request_payload,
            timeout=30
        )
        
        if response.status_code == 200:
            response_data = response.json()
            result = _format_vision_response(response_data, element_info)
            
            # ‡πÅ‡∏õ‡∏•‡∏á HTML tables ‡πÄ‡∏õ‡πá‡∏ô Markdown (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            result = convert_html_tables_to_markdown(result)
            
            detection_info = f" (using {detection_type})"
            merged_info = f" (merged: {element_info.get('merged_count', 1)} elements)" if element_info and element_info.get('merged_count', 1) > 1 else ""
            print(f"    -> ‚úÖ Google Vision OCR success{detection_info}{merged_info}")
            return result
            
        else:
            error_msg = f"HTTP {response.status_code}: {response.text}"
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö rate limit errors
            if response.status_code == 429 or 'quota' in response.text.lower():
                if retry_count < max_retries:
                    print(f"    -> ‚ö†Ô∏è Rate limit/quota hit, retrying in {2 ** retry_count * 2}s...")
                    time.sleep(2 ** retry_count * 2)  # exponential backoff
                    return _google_vision_process_crop(pil_image_crop, element_info, retry_count + 1, max_retries)
                else:
                    return f"[Vision API Error: Rate limit exceeded after {max_retries + 1} attempts]"
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö authentication errors
            elif response.status_code == 401:
                return "[Vision API Error: Invalid API key]"
            
            # errors ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
            else:
                if retry_count < max_retries:
                    print(f"    -> ‚ö†Ô∏è Vision API error (HTTP {response.status_code}), retrying...")
                    time.sleep(2)
                    return _google_vision_process_crop(pil_image_crop, element_info, retry_count + 1, max_retries)
                else:
                    return f"[Vision API Error: {error_msg}]"
                
    except requests.exceptions.Timeout:
        if retry_count < max_retries:
            print(f"    -> ‚ö†Ô∏è Request timeout, retrying...")
            time.sleep(3)
            return _google_vision_process_crop(pil_image_crop, element_info, retry_count + 1, max_retries)
        else:
            return f"[Vision API Error: Timeout after {max_retries + 1} attempts]"
    
    except Exception as e:
        print(f"    -> ‚ùå Google Vision API error: {e}")
        return f"[Vision API Error: {str(e)}]"

# --- HybridProcessor Class ---
class HybridProcessor:
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path
        _initialize_surya_models()

    def run(self) -> list:
        all_pages_content = []
        try:
            print(f"Processing Hybrid (Surya+Google Vision) on PDF: {self.pdf_path.name}")
            with fitz.open(self.pdf_path) as doc:
                print(f"üìÑ ‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {doc.page_count} ‡∏´‡∏ô‡πâ‡∏≤ ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤...")
                for page_num_zero_based in range(doc.page_count):
                    page_num_one_based = page_num_zero_based + 1
                    print(f"\n{'='*20} Processing Page {page_num_one_based}/{doc.page_count} {'='*20}")
                    page = doc.load_page(page_num_zero_based)
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á PDF page ‡πÄ‡∏õ‡πá‡∏ô image
                    pix = page.get_pixmap(dpi=200)
                    pil_image = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
                    
                    # Stage 1: Layout Analysis ‡∏î‡πâ‡∏ß‡∏¢ Surya (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏° bbox)
                    print(f" -- Page {page_num_one_based}: Stage 1 - Layout Analysis with Surya...")
                    elements = _surya_layout_analysis(pil_image)
                    print(f" -- Page {page_num_one_based}: Found {len(elements)} layout elements (sorted by reading order).")

                    # Stage 2: OCR ‡πÅ‡∏ï‡πà‡∏•‡∏∞ element ‡∏î‡πâ‡∏ß‡∏¢ Google Vision (‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß)
                    print(f" -- Page {page_num_one_based}: Stage 2 - OCR each element with Google Vision (following reading order)...")
                    page_content_parts = []
                    total_elements = len(elements)
                    
                    for i, elem in enumerate(elements):
                        bbox = [int(coord) for coord in elem['bbox']]
                        
                        merged_info = f" (merged: {elem.get('merged_count', 1)} elements)" if elem.get('merged_count', 1) > 1 else ""
                        print(f"    -> Processing element {i+1}/{total_elements} (type: {elem['label']}, conf: {elem['confidence']:.3f}){merged_info}...")
                        
                        # Crop ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏≤‡∏° bbox ‡∏ó‡∏µ‡πà‡∏Ç‡∏¢‡∏≤‡∏¢‡πÅ‡∏•‡πâ‡∏ß
                        try:
                            cropped_image = pil_image.crop(tuple(bbox))
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ crop ‡πÑ‡∏î‡πâ‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
                            if cropped_image.size[0] < 10 or cropped_image.size[1] < 10:
                                print(f"    -> ‚ö†Ô∏è Skipping too small crop: {cropped_image.size}")
                                continue
                                
                            # ‡∏™‡πà‡∏á‡πÑ‡∏õ OCR ‡∏î‡πâ‡∏ß‡∏¢ Google Vision (‡∏û‡∏£‡πâ‡∏≠‡∏° retry logic)
                            markdown_text = _google_vision_process_crop(cropped_image, elem)
                            if markdown_text.strip() and not markdown_text.startswith('[Vision API Error:') and not markdown_text.startswith('[Error:'):
                                page_content_parts.append(markdown_text.strip())
                                print(f"    -> ‚úÖ Successfully extracted text from element {i+1}")
                            elif markdown_text.startswith('[Vision API Error:') or markdown_text.startswith('[Error:'):
                                print(f"    -> ‚ö†Ô∏è OCR failed for element {i+1}: {markdown_text}")
                                # ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏Å‡πá‡∏ö error message ‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏õ‡∏±‡∏ç‡∏´‡∏≤
                                page_content_parts.append(markdown_text)
                            else:
                                print(f"    -> ‚ÑπÔ∏è No text found in element {i+1}")
                                
                        except Exception as e:
                            print(f"    -> ‚ö†Ô∏è Error processing element {i+1}: {e}")
                            continue
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
                    success_count = sum(1 for part in page_content_parts if not (part.startswith('[Vision API Error:') or part.startswith('[Error:')))
                    error_count = len(page_content_parts) - success_count
                    print(f" -- Page {page_num_one_based}: OCR Results - Success: {success_count}, Errors: {error_count}")
                    
                    # Stage 3: ‡∏£‡∏ß‡∏° results ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô
                    print(f" -- Page {page_num_one_based}: Stage 3 - Merging results in reading order...")
                    final_markdown_for_page = "\n\n".join(filter(None, page_content_parts))
                    
                    if not final_markdown_for_page.strip():
                        final_markdown_for_page = f"[No readable content found on page {page_num_one_based}]"
                    else:
                        # ‡πÄ‡∏û‡∏¥‡πà‡∏° header ‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏ô‡πâ‡∏≤
                        final_markdown_for_page = f"## Page {page_num_one_based}\n\n{final_markdown_for_page}"
                    
                    all_pages_content.append(final_markdown_for_page)
                    print(f" -- Page {page_num_one_based}: Successfully processed with proper reading order.")

            print(f"\nüéâ Successfully processed all {len(all_pages_content)} pages with improved layout ordering using Google Vision!")
            return all_pages_content
            
        except Exception as e:
            print(f"‚ùå Error processing {self.pdf_path.name}: {e}")
            traceback.print_exc()
            return [f"An error occurred while processing {self.pdf_path.name}: {e}"]